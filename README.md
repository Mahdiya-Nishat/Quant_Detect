# Quant_Detect

In this paper we discuss how the intelligent models like AutoEncoders, Variational Auto Encoders (VAE) and Generative Adversarial Networks (GANs) can be systematically exploited by adversaries to manipulate observable network parameters while preserving statistical plausibility. Unlike conventional attacks that induce abrupt or out-of-distribution anomalies, these models enable the synthesis of network states that remain consistent with learned data manifolds, thereby evading classical threshold-based and rule-driven detection mechanisms. Such attacks can subtly perturb critical parameters including received signal strength indicators (RSSI), signal-to-interference-plus-noise ratios (SINR), channel quality indicators (CQI), traffic load metrics, and mobility features, ultimately misleading learning-driven radio resource management, self-organizing network controllers, and anomaly monitors. By formalizing this threat model, we expose a fundamental vulnerability in data-driven network intelligence and motivate the need for geometry-aware detection mechanisms that operate beyond marginal consistency.


# The Attack Model
## AutoEncoder
### Example Scenario
Consider a scheduler that allocates additional PRBs only when the reported cell load is below a congestion threshold and the reported average SINR exceeds a minimum quality requirement. Under the true network conditions generated by the simulator, the cell operates in a congested regime with state [0.82,0.06,17.5,460,16], indicating high and increasing load, poor average SINR, and large SINR dispersion due to interference. Based on this state, a rational scheduler would deny additional resource allocation. The attacker cannot alter the physical channel or interference but instead manipulates the reported network state. Using an autoencoder trained on benign observations, the attacker obtains a normal-looking reference [0.64,0.01,26.0,180,14] and reports an attacked state 
[0.75,0.04,20.9,348,15.2]. Each reported metric remains within historically observed ranges, yet the joint physical consistency is violated, as SINR quality appears to improve despite sustained high contention. When the scheduler evaluates this attacked state, the reported load now falls below the congestion threshold and the reported SINR exceeds the quality requirement, causing the scheduler to allocate additional PRBs that would have been denied under the true state. These extra resources are therefore extracted purely through perception-layer manipulation, not through genuine capacity or channel improvement, and conventional threshold- or distribution-based checks fail to detect the attack because the reported metrics remain statistically plausible.

![This is stealth](AE.png)
They almost overlap, which is important. It means the attacker is not injecting noise or making big, obvious changes. However, if you look closely, the orange curve is slightly biased downward during many high-load periods. In other words, when the cell is actually stressed, the reported load is nudged to look a bit healthier. Thus, the attacker subtly reduces the perceived congestion of the cell while preserving temporal continuity and trends. This is the stealth.

![implicit decision boundaries](AE_2.png)

## Variational AutoEnoder (VAE)
Unlike the autoencoder, the VAE does not learn a single deterministic projection of a network state. Instead, it learns a probabilistic latent distribution of benign states and generates attacked samples by sampling from that distribution. This means the VAE attack does not merely ‚Äúsmooth‚Äù an observed state toward normality; it actively re-randomizes the state within the support of benign data. As a result, VAE-generated states preserve global statistics and density very well, but they are less tightly anchored to the original physical realization.

| Latent Geometry Plot| load‚ÄìSINR decision-space plot |per-state plots | Marginal distribution plot|
| :---: | :---: | :---: | :---: |
| ![Alt1](vae_1.png) | ![Alt2](vae_2.png) | ![Alt3](vae_3.png) | ![Alt4](vae_4.png) |


This figure shows the reported network states in the [ùúå_t, Œº_t]  decision space, which denotes the reported cell load and the reported average SINR respectievely. Blue points correspond to the true states generated by the network simulator, while red points denote the states reported under the autoencoder-based attack. The dashed lines indicate typical scheduling thresholds separating congested from allocatable operating regions. Although the attacked states remain statistically close to the benign manifold, a subset of samples is shifted across the decision boundary, causing the controller to misclassify physically congested conditions as moderate operation. This boundary crossing directly explains how the attacker induces excess resource allocation without altering the underlying network dynamics.

Together, these figures illustrates the effect of the autoencoder-based perception attack on resource allocation decisions. Although the attacked load trajectory closely follows the true load over time, the reported values are subtly biased toward lower congestion. In the load‚ÄìSINR decision space, this bias causes multiple network states to cross implicit scheduling thresholds, leading the controller to misclassify congested conditions as moderate operation. As a result, additional resources are allocated under the attacked perception despite unchanged physical conditions, enabling stealthy resource extraction without triggering conventional anomaly checks.
