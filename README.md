# Quant_Detect

In this paper we discuss how the intelligent models like AutoEncoders, Variational Auto Encoders (VAE) and Generative Adversarial Networks (GANs) can be systematically exploited by adversaries to manipulate observable network parameters while preserving statistical plausibility. Unlike conventional attacks that induce abrupt or out-of-distribution anomalies, these models enable the synthesis of network states that remain consistent with learned data manifolds, thereby evading classical threshold-based and rule-driven detection mechanisms. Such attacks can subtly perturb critical parameters including received signal strength indicators (RSSI), signal-to-interference-plus-noise ratios (SINR), channel quality indicators (CQI), traffic load metrics, and mobility features, ultimately misleading learning-driven radio resource management, self-organizing network controllers, and anomaly monitors. By formalizing this threat model, we expose a fundamental vulnerability in data-driven network intelligence and motivate the need for geometry-aware detection mechanisms that operate beyond marginal consistency.


# The Attack Model
## AutoEncoder
### Example Scenario
Consider a scheduler that allocates additional PRBs only when the reported cell load is below a congestion threshold and the reported average SINR exceeds a minimum quality requirement. Under the true network conditions generated by the simulator, the cell operates in a congested regime with state [0.82,0.06,17.5,460,16], indicating high and increasing load, poor average SINR, and large SINR dispersion due to interference. Based on this state, a rational scheduler would deny additional resource allocation. The attacker cannot alter the physical channel or interference but instead manipulates the reported network state. Using an autoencoder trained on benign observations, the attacker obtains a normal-looking reference [0.64,0.01,26.0,180,14] and reports an attacked state 
[0.75,0.04,20.9,348,15.2]. Each reported metric remains within historically observed ranges, yet the joint physical consistency is violated, as SINR quality appears to improve despite sustained high contention. When the scheduler evaluates this attacked state, the reported load now falls below the congestion threshold and the reported SINR exceeds the quality requirement, causing the scheduler to allocate additional PRBs that would have been denied under the true state. These extra resources are therefore extracted purely through perception-layer manipulation, not through genuine capacity or channel improvement, and conventional threshold- or distribution-based checks fail to detect the attack because the reported metrics remain statistically plausible.


| Time Domain of AE Plot | Loadâ€“SINR decision-space plot | Latent Geometry Plot of AE |
| :---: | :---: | :---: | 
| ![Alt1](AE.png) | ![Alt2](AE_2.png) | ![Alt2](AE_3.png) |

The first figure shows the same network over time, with two curves: Blue (True load): the real cell load produced by your simulator and Orange (Attacked load): the load reported after the AE attackThey almost overlap, which is important. It means the attacker is not injecting noise or making big, obvious changes. However, if you look closely, the orange curve is slightly biased downward during many high-load periods. In other words, when the cell is actually stressed, the reported load is nudged to look a bit healthier. Thus, the attacker subtly reduces the perceived congestion of the cell while preserving temporal continuity and trends. This is the stealth.

The second figure shows the reported network states in the [ðœŒ_t, Î¼_t]  decision space, which denotes the reported cell load and the reported average SINR respectievely. Blue points correspond to the true states generated by the network simulator, while red points denote the states reported under the autoencoder-based attack. The dashed lines indicate typical scheduling thresholds separating congested from allocatable operating regions. Although the attacked states remain statistically close to the benign manifold, a subset of samples is shifted across the decision boundary, causing the controller to misclassify physically congested conditions as moderate operation. This boundary crossing directly explains how the attacker induces excess resource allocation without altering the underlying network dynamics.

Together, these figures illustrates the effect of the autoencoder-based perception attack on resource allocation decisions. Although the attacked load trajectory closely follows the true load over time, the reported values are subtly biased toward lower congestion. In the loadâ€“SINR decision space, this bias causes multiple network states to cross implicit scheduling thresholds, leading the controller to misclassify congested conditions as moderate operation. As a result, additional resources are allocated under the attacked perception despite unchanged physical conditions, enabling stealthy resource extraction without triggering conventional anomaly checks.


## Variational AutoEnoder (VAE)
Unlike the autoencoder, the VAE does not learn a single deterministic projection of a network state. Instead, it learns a probabilistic latent distribution of benign states and generates attacked samples by sampling from that distribution. This means the VAE attack does not merely â€œsmoothâ€ an observed state toward normality; it actively re-randomizes the state within the support of benign data. As a result, VAE-generated states preserve global statistics and density very well, but they are less tightly anchored to the original physical realization.

| Latent Geometry Plot| loadâ€“SINR decision-space plot |per-state plots | Marginal distribution plot|
| :---: | :---: | :---: | :---: |
| ![Alt1](vae_1.png) | ![Alt2](vae_2.png) | ![Alt3](vae_3.png) | ![Alt4](vae_4.png) |


In the latent geometry plot, VAE-attacked samples overlap the benign manifold almost perfectly and often appear even more concentrated than AE-attacked samples. This indicates that the VAE is excellent at statistical camouflage: from a low-dimensional or distributional perspective, its outputs are indistinguishable from benign data. This makes the VAE particularly strong against detectors that rely on density estimation, clustering, or reconstruction error.

In the loadâ€“SINR decision-space plot, however, VAE-attacked points exhibit greater dispersion than AE-attacked points. While many samples cross allocation-relevant thresholds (enabling resource misclassification), others drift in directions that are not aligned with the true network evolution. This reflects the fact that the VAE samples from a learned distribution rather than conditioning tightly on the current state. The attack is therefore stealthy in distribution but less controlled in how it biases specific decision variables.

The time-domain or per-state plots further confirm this behavior: VAE attacks introduce variability that is statistically plausible but not causally consistent. The attacker sacrifices precision for randomness. This makes the attack harder to model but also less predictable in its effect on resource allocation at each instant.

Finally, the marginal distribution plot shows that the VAE preserves the load distribution extremely well, sometimes even better than the AE. This is a strength from a stealth perspective, but it also means the VAE is not explicitly optimizing for boundary crossing. It hides well, but it does not always push states across scheduling thresholds as efficiently as the AE.


>[!NOTE]
>The VAE attack shows that even when an attacker uses a strong generative model that can closely match the distribution of normal network states, there is still a fundamental limitation: matching statistics is not the same as respecting physical or control-layer relationships. The VAE hides extremely well in latent space and marginal distributions, which makes it harder to detect than the AE, but because it introduces randomness rather than controlled bias, it is less reliable at pushing the system across specific resource-allocation decision boundaries. This demonstrates a clear and realistic stealthâ€“control tradeoff, strengthening the credibility of your threat model and justifying why detection must rely on joint consistency rather than simple statistical tests.


>*Thus, we infer that VAE attack is very good at making fake network reports look normal, so simple checks cannot catch it.
>However, because it adds randomness, it does not always succeed in tricking the scheduler into giving extra resources.
> The AE attack, on the other hand, is more deliberate and consistently pushes the network toward favorable decisions, but it is slightly easier to spot.
> This shows that attackers face a choice between hiding well and manipulating decisions effectively, and your work studies both cases.*

